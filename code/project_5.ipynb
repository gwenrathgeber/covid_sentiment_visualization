{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "code",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RvAm7m1J4_HZ",
        "colab_type": "text"
      },
      "source": [
        "# Problem Statement "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "waW1jw1V74lN",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Problem Statement: The COVID-19 response has been largely regional and state-based in nature. Some states have enacted strictly enforced stay-at-home policies, while others have provided guidelines. It would be worthwhile to compare the sentiment analysis of tweets across the United States and compare them to both the local policies on social distancing and the occurrences of the pandemic in those areas.\n",
        "\n",
        "Suggestions for Deliverables:\n",
        "\n",
        "- A short write up describing the project, results, and next steps or proposal to scale\n",
        "- Open source code for identifying social media posts from specific regions and conducting a sentiment analysis or topic extraction on that data\n",
        "\n",
        "Descriptions of input data:\n",
        "\n",
        "- Twitter tweets \n",
        "- Government data on social distancing policies\n",
        "- Health related data on COVID-19 occurrences in that region"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzAZk7uZ4_EP",
        "colab_type": "text"
      },
      "source": [
        "# Executive Summary \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iH_nHYuV8NzB",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cxucZ9t4_BB",
        "colab_type": "text"
      },
      "source": [
        "# Contents "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d45eHK_K8OmP",
        "colab_type": "text"
      },
      "source": [
        "- [Data Dictionary](#Data-Dictionary)\n",
        "- [Package Import](#Package-Import)\n",
        "- [Scraping COVID-19 Geo Tagged Tweet URLs](#Scraping-COVID-19-Geo-Tagged-Tweet-URLs)\n",
        "- [Hydrating Tweets using TWARC API](#Hydrating-Tweets-using-TWARC-API)\n",
        "- [Exploratory Data Analysis (EDA)](#Exploratory-Data-Analysis-(EDA))\n",
        "- [Modeling](#Modeling)\n",
        "- [Model Selection](#Model-Selection)\n",
        "- [Model Evaluation](#Model-Evaluation)\n",
        "- [Conclusions and Recommendations](#Conclusions-and-Recommendations)\n",
        "- [Reference](#Reference)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVDzsSsj4-9O",
        "colab_type": "text"
      },
      "source": [
        "# Data Dictionary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0CzJla59yCG",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u20S3yVr4-0A",
        "colab_type": "text"
      },
      "source": [
        "# Package Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTMT3Zkw7AB8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Standard Packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "#Modeling Packages\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.feature_extraction import stop_words\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.pipeline import Pipeline \n",
        "\n",
        "#Twitter \n",
        "# pip install textblob \n",
        "from textblob import TextBlob \n",
        "import re \n",
        "\n",
        "\n",
        "\n",
        "pd.set_option('display.max_columns', 100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rp5q6cmr6vAj",
        "colab_type": "text"
      },
      "source": [
        "# Scraping COVID-19 Geo Tagged Tweet URLs \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oo8zBFp57PqF",
        "colab_type": "text"
      },
      "source": [
        "The twitter scraping process can be found in the get_tweet_ids.ipynb Jupyter notebook. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AdwoUvmD4-eJ",
        "colab_type": "text"
      },
      "source": [
        "# Hydrating Tweets using TWARC API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0uNk2887l8d",
        "colab_type": "text"
      },
      "source": [
        "The hydrating tweet urls to obtain the tweets process can be found in the hydrate_tweets.ipynb Jupyter notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUlniPTH5sSD",
        "colab_type": "text"
      },
      "source": [
        "# Exploratory Data Analysis (EDA)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YzXZUXMBCrtg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_tweets = []\n",
        "with open('/content/tweets.jsonl', 'r') as json_file:\n",
        "    json_list = list(json_file)\n",
        "\n",
        "for json_str in json_list:\n",
        "    try:\n",
        "      result = json.loads(json_str)\n",
        "      all_tweets.append(result)\n",
        "    except:\n",
        "      pass\n",
        "    #print(\"result: {}\".format(result))\n",
        "    #print(isinstance(result, dict))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndnt0jOFIOEs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "19a40e8b-1b74-4908-91ca-9782afe739d8"
      },
      "source": [
        "len(all_tweets)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bxqVtV5IGqd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "335b789a-937c-4180-d781-6a169258e649"
      },
      "source": [
        "len([tweet for tweet in all_tweets if type(tweet['place']) == dict])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdnHUCseCvVb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_tweets = [tweet for tweet in all_tweets if type(tweet['place']) == dict]\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBdQHSOIoIU-",
        "colab_type": "text"
      },
      "source": [
        "## Analyzing Twitter data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lqk7djVIluRD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://medium.com/shiyan-boxer/2020-us-presidential-election-twitter-sentiment-analysis-and-visualization-89e58a652af5\n",
        "\n",
        "class TweetAnalyzer():\n",
        "    \"\"\"\n",
        "    Functionality for analyzing and categorizing content from tweets.\n",
        "    \"\"\"\n",
        "\n",
        "    def clean_tweet(self, tweet):\n",
        "        return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", tweet).split())\n",
        "\n",
        "    def analyze_sentiment(self, tweet):\n",
        "        return TextBlob(self.clean_tweet(tweet))\n",
        "        \n",
        "    def tweets_to_data_frame(self, tweets):\n",
        "        df = pd.DataFrame(data=[tweet['full_text'] for tweet in tweets], columns=['full_text'])\n",
        "        df['id'] = np.array([tweet['id'] for tweet in tweets])\n",
        "        df['date'] = np.array([tweet['created_at'] for tweet in tweets])\n",
        "        df['city'] = [tweet['place']['full_name'] for tweet in tweets]\n",
        "        df['country_code'] = [tweet['place']['country_code'] for tweet in tweets]\n",
        "        df['country'] = [tweet['place']['country'] for tweet in tweets]\n",
        "        df['coordinates'] = [tweet['coordinates']['coordinates'] for tweet in tweets]\n",
        "\n",
        "        return df\n",
        "\n",
        " \n",
        "# if __name__ == '__main__':\n",
        "\n",
        "#     twitter_client = TwitterClient()\n",
        "#     tweet_analyzer = TweetAnalyzer()\n",
        "\n",
        "#     api = twitter_client.get_twitter_client_api()\n",
        "\n",
        "#     tweets = api.user_timeline(screen_name=\"realDonaldTrump\", count=20)\n",
        "\n",
        "#     # Demonstrations of possible EDA information \n",
        "#     #print(dir(tweets[0]))\n",
        "#     #print(tweets[0].retweet_count)\n",
        "\n",
        "#     df = tweet_analyzer.tweets_to_data_frame(tweets)\n",
        "#     print(df.head(10))\n",
        "\n",
        "#\"\"\" Sentiment Analysis \"\"\"\n",
        "    #df['sentiment'] = np.array([tweet_analyzer.analyze_sentiment(tweet) for tweet in df['tweets']])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDXX2W7YIDD-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dfe93b62-6604-4adb-8a8a-591b9ca56993"
      },
      "source": [
        "all_tweets"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHa6dYtQGg19",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "outputId": "a3c9239f-4daf-4a73-8760-70f56e9def32"
      },
      "source": [
        "test_tweet = all_tweets[0]\n",
        "\n",
        "\n",
        "test_tweet['place']['full_name']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-a14dd896f332>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_tweet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_tweets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtest_tweet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'place'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'full_name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mucQN9LkF5yn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "be8400e2-4d90-4fbd-9391-322face92438"
      },
      "source": [
        "ta = TweetAnalyzer()\n",
        "df = ta.tweets_to_data_frame(all_tweets)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-de9cf3dedb06>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTweetAnalyzer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtweets_to_data_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_tweets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-42-0d0ac47ce449>\u001b[0m in \u001b[0;36mtweets_to_data_frame\u001b[0;34m(self, tweets)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtweet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtweet\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtweets\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtweet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'created_at'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtweet\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtweets\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'city'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtweet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'place'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'full_name'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtweet\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtweets\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'country_code'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtweet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'place'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'country_code'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtweet\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtweets\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'country'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtweet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'place'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'country'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtweet\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtweets\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-42-0d0ac47ce449>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtweet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtweet\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtweets\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtweet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'created_at'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtweet\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtweets\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'city'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtweet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'place'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'full_name'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtweet\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtweets\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'country_code'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtweet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'place'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'country_code'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtweet\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtweets\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'country'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtweet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'place'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'country'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtweet\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtweets\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDyF7MzuoNHV",
        "colab_type": "text"
      },
      "source": [
        "## Visualizing Twitter data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9wqhPbJm0bm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get average length over all tweets:\n",
        "print(np.mean(df['len']))\n",
        "\n",
        "# Get the number of likes for the most liked tweet:\n",
        "print(np.max(df['likes']))\n",
        "\n",
        "# Get the number of retweets for the most retweeted tweet:\n",
        "print(np.max(df['retweets']))\n",
        "\n",
        "print(df.head(10))\n",
        "\n",
        "# Time Series\n",
        "# time_likes = pd.Series(data=df['len'].values, index=df['date'])\n",
        "# time_likes.plot(figsize=(16, 4), color='r')\n",
        "# plt.show()\n",
        "\n",
        "# time_favs = pd.Series(data=df['likes'].values, index=df['date'])\n",
        "# time_favs.plot(figsize=(16, 4), color='r')\n",
        "# plt.show()\n",
        "\n",
        "# time_retweets = pd.Series(data=df['retweets'].values, index=df['date'])\n",
        "# time_retweets.plot(figsize=(16, 4), color='r')\n",
        "# plt.show()\n",
        "\n",
        "# Layered Time Series:\n",
        "time_likes = pd.Series(data=df['likes'].values, index=df['date'])\n",
        "time_likes.plot(figsize=(16, 4), label=\"likes\", legend=True)\n",
        "\n",
        "time_retweets = pd.Series(data=df['retweets'].values, index=df['date'])\n",
        "time_retweets.plot(figsize=(16, 4), label=\"retweets\", legend=True)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDTlUI3GAPjK",
        "colab_type": "text"
      },
      "source": [
        "# Unsupervised Sentiment Analysis "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJ4TYPsDATFn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PxWzmel34M8n",
        "colab_type": "text"
      },
      "source": [
        "# Modeling "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCGAkjO_4pd4",
        "colab_type": "text"
      },
      "source": [
        "## Model Preparation "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6wokT1E413b",
        "colab_type": "text"
      },
      "source": [
        "### Instantiating feature and target variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "foABEkJC6G0e",
        "colab_type": "text"
      },
      "source": [
        "## Model Selection "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73-Gl6UC6Gwu",
        "colab_type": "text"
      },
      "source": [
        "## Model Evaluation "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VedZWcXL6GtP",
        "colab_type": "text"
      },
      "source": [
        "# Conclusions and Recommendations "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zszvWu3d6Gmx",
        "colab_type": "text"
      },
      "source": [
        "# References "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHnKjLgR4MP2",
        "colab_type": "text"
      },
      "source": [
        "- COVID-19 Geo Tagged Tweets Dataset: https://ieee-dataport.org/open-access/coronavirus-covid-19-geo-tagged-tweets-dataset\n",
        "- Package for Hydrating Tweets: https://github.com/DocNow/twarc\n",
        "- Unsupervised Sentiment Analysis (K Means Clustering): https://towardsdatascience.com/unsupervised-sentiment-analysis-a38bf1906483\n",
        "- Recommended Python libraries for Sentiment Analysis: https://www.iflexion.com/blog/sentiment-analysis-python\n",
        "- Everything You Need to Know About Sentiment Analysis: https://monkeylearn.com/sentiment-analysis/\n",
        "- Twitter Sentiment Analysis with Python and NLTK: http://www.laurentluce.com/posts/twitter-sentiment-analysis-using-python-and-nltk/\n",
        "- Is it possible to do sentiment analysis of unlabelled text using word2vec model?: https://stackoverflow.com/questions/61185290/is-it-possible-to-do-sentiment-analysis-of-unlabelled-text-using-word2vec-model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSlNfIaqNSL7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}